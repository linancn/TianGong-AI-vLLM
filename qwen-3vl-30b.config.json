{
  "apps": [
    {
      "name": "vllm-qwen-3vl-30b",
      "script": "/bin/bash",
      "args": [
        "-lc",
        "source .venv/bin/activate && VLLM_USE_MODELSCOPE=True python -m vllm.entrypoints.openai.api_server --model Qwen/Qwen3-VL-30B-A3B-Instruct-FP8 --max-model-len 16384 --port 8002"
      ],
      "interpreter": "none",
      "env": {
        "CUDA_VISIBLE_DEVICES": "2"
      },
      "autorestart": true,
      "watch": false,
      "error_file": "./logs/vllm-qwen-3vl-30b-error.log",
      "out_file": "./logs/vllm-qwen-3vl-30b-out.log",
      "merge_logs": true,
      "time": true
    }
  ]
}